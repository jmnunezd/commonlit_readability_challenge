{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# First analysis","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"markdown","source":"### Importing libraries and settings","metadata":{}},{"cell_type":"code","source":"!pip install Textstat","metadata":{"execution":{"iopub.status.busy":"2021-05-21T01:44:36.645373Z","iopub.execute_input":"2021-05-21T01:44:36.64613Z","iopub.status.idle":"2021-05-21T01:44:46.210894Z","shell.execute_reply.started":"2021-05-21T01:44:36.646075Z","shell.execute_reply":"2021-05-21T01:44:46.209965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport textstat\nfrom sklearn import preprocessing\nfrom collections import defaultdict\nimport nltk\nfrom nltk.corpus import stopwords\nimport math","metadata":{"execution":{"iopub.status.busy":"2021-05-21T01:44:46.214944Z","iopub.execute_input":"2021-05-21T01:44:46.215277Z","iopub.status.idle":"2021-05-21T01:44:47.288963Z","shell.execute_reply.started":"2021-05-21T01:44:46.215238Z","shell.execute_reply":"2021-05-21T01:44:47.287857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.set_option('display.max_columns', None)\npd.set_option('display.width', None)\npd.set_option('display.max_colwidth', -1)","metadata":{"execution":{"iopub.status.busy":"2021-05-21T01:44:47.290766Z","iopub.execute_input":"2021-05-21T01:44:47.291109Z","iopub.status.idle":"2021-05-21T01:44:47.296913Z","shell.execute_reply.started":"2021-05-21T01:44:47.291032Z","shell.execute_reply":"2021-05-21T01:44:47.295681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Reading competition training data","metadata":{}},{"cell_type":"code","source":"all_df = pd.read_csv('/kaggle/input/commonlitreadabilityprize/train.csv')\ndf = all_df[['id', 'excerpt', 'target', 'standard_error']]","metadata":{"execution":{"iopub.status.busy":"2021-05-21T01:45:20.440234Z","iopub.execute_input":"2021-05-21T01:45:20.44072Z","iopub.status.idle":"2021-05-21T01:45:20.491388Z","shell.execute_reply.started":"2021-05-21T01:45:20.44067Z","shell.execute_reply":"2021-05-21T01:45:20.490253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(all_df.shape, '\\n')\nall_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-05-21T01:56:33.510255Z","iopub.execute_input":"2021-05-21T01:56:33.510735Z","iopub.status.idle":"2021-05-21T01:56:33.529903Z","shell.execute_reply.started":"2021-05-21T01:56:33.510698Z","shell.execute_reply":"2021-05-21T01:56:33.528668Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['target'].hist(bins=30)","metadata":{"execution":{"iopub.status.busy":"2021-05-21T01:44:30.851187Z","iopub.status.idle":"2021-05-21T01:44:30.85209Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Reading English frequency data I found","metadata":{}},{"cell_type":"code","source":"with open('/kaggle/input/en-word-frequency/en_50k.txt', 'r') as f:\n    data = f.read()\n    data = data.split()\n    \n    words = data[0::2]\n    freqs = data[1::2]\n    \n    freq = defaultdict(lambda: 0, {k: int(v) for k, v in zip(words, freqs)})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"demo_str = \"I am a nasty old pirate, get close to me lad and you'll know all the secrests across all seven seas\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a = [1,2,3,4,2,2,2,2]\na.remove(2)\na","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stopwords_list = stopwords.words('english')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a = [word for word in demo_str.split() if word not in stopwords_list]\na","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# TODO: right now the final value is heavily influenced by stopwords that are very common, we should get rid of them.\ndef rarity(excerpt):\n    \"\"\"the lower the output is, the more rare the excerpt is\"\"\"\n    excerpt = excerpt.lower()\n    excerpt = excerpt.replace('?', '').replace('.', '').replace(',', '').replace('!', '')\n    \n    excerpt_words = {word for word in excerpt.split() if word not in stopwords_list}\n    \n    suma = 0\n    for word in excerpt_words:\n        suma += freq[word]\n\n    avg = suma / len(excerpt.split())\n\n    return int(avg)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### This is the more complex excerpt in the train data:","metadata":{}},{"cell_type":"code","source":"df.sort_values('target')['excerpt'].iloc[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rarity(df.sort_values('target')['excerpt'].iloc[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### This is the easiest excerpt in the train data:","metadata":{}},{"cell_type":"code","source":"df.sort_values('target')['excerpt'].iloc[-1]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rarity(df.sort_values('target')['excerpt'].iloc[-1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### applying rarity index to all the datapoints:","metadata":{}},{"cell_type":"code","source":"df['rarity'] = df['excerpt'].apply(lambda value: rarity(value))\n\n# standarizing between 0 an 1:\nminimum = df['rarity'].min()\nmaximum = df['rarity'].max()\n\n\ndf['rarity'] = (df['rarity'] - minimum)/(maximum - minimum)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['rarity'].hist(bins=30)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['longitude'] = df['excerpt'].apply(lambda value: len(value))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['longitude'].hist(bins=30)\n# we need to do something about the difference in the ammount of words per excerpt.","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['punctuation_marks'] = df['excerpt'].apply(lambda value: value.count('?') + value.count('.') + value.count(',') + value.count('!'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def num_unique_words(text):\n    text = text.lower()\n    text = text.replace('?', '').replace('.', '').replace(',', '').replace('!', '')\n    \n    text_set = set(text.split())\n    return len(text_set)\n\ndf['num_diff_words'] = df['excerpt'].apply(lambda value: num_unique_words(value))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# flesch_reading_ease test\ndf['fre_test'] = df['excerpt'].apply(lambda value: textstat.flesch_reading_ease(value))\n\n# standarizing between 0 an 1:\nminimum = df['fre_test'].min()\nmaximum = df['fre_test'].max()\n\n\ndf['fre_test'] = (df['fre_test'] - minimum)/(maximum - minimum)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# flesch_reading_ease test\ndf['fkg_test'] = df['excerpt'].apply(lambda value: textstat.flesch_kincaid_grade(value))\n\n# standarizing between 0 an 1:\nminimum = df['fkg_test'].min()\nmaximum = df['fkg_test'].max()\n\n\ndf['fkg_test'] = (df['fkg_test'] - minimum)/(maximum - minimum)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# flesch_reading_ease test\ndf['gf_test'] = df['excerpt'].apply(lambda value: textstat.gunning_fog(value))\n\n# standarizing between 0 an 1:\nminimum = df['gf_test'].min()\nmaximum = df['gf_test'].max()\n\n\ndf['gf_test'] = (df['gf_test'] - minimum)/(maximum - minimum)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# flesch_reading_ease test\ndf['s_test'] = df['excerpt'].apply(lambda value: textstat.smog_index(value))\n\n# standarizing between 0 an 1:\nminimum = df['s_test'].min()\nmaximum = df['s_test'].max()\n\n\ndf['s_test'] = (df['s_test'] - minimum)/(maximum - minimum)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# flesch_reading_ease test\ndf['dcrs_test'] = df['excerpt'].apply(lambda value: textstat.dale_chall_readability_score(value))\n\n# standarizing between 0 an 1:\nminimum = df['dcrs_test'].min()\nmaximum = df['dcrs_test'].max()\n\n\ndf['dcrs_test'] = (df['dcrs_test'] - minimum)/(maximum - minimum)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['dcrs_test'].hist(bins=30)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# standarize numeric values by the number of words in the excerpt:\ndf['punctuation_marks'] = df['punctuation_marks'] / df['longitude']\ndf['num_diff_words'] = df['num_diff_words'] / df['longitude']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.corr()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.plot.scatter(x='rarity', y='target')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.plot.scatter(x='dcrs_test', y='target')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.plot.scatter(x='dcrs_test', y='rarity', color='red')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.plot.scatter(x='punctuation_marks', y='fre_test', c='target', colormap='viridis')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.plot.scatter(x='rarity', y='fre_test', c='target', colormap='viridis')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.plot.scatter(x='dcrs_test', y='rarity', c='target', colormap='viridis')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.svm import SVR","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head(1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y = df['target'].values","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = df[['rarity', 'fre_test']].values\nX","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"regr = SVR()\nregr.fit(X, Y)\n\npred = regr.predict(X)\ndf['pred'] = pred\n\ndf['error'] = (df['target'] - df['pred'])**2\n\nmse = df['error'].mean()\nrmse = math.sqrt(mse)\nrmse","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = df[['rarity', 'dcrs_test']].values\nX","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"regr = SVR()\nregr.fit(X, Y)\n\npred = regr.predict(X)\ndf['pred'] = pred\n\ndf['error'] = (df['target'] - df['pred'])**2\n\nmse = df['error'].mean()\nrmse = math.sqrt(mse)\nrmse","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# With a C=2 to see what happends\n\nregr = SVR(C=2, kernel='poly', degree=5)\nregr.fit(X, Y)\n\npred = regr.predict(X)\ndf['pred'] = pred\n\ndf['error'] = (df['target'] - df['pred'])**2\n\nmse = df['error'].mean()\nrmse = math.sqrt(mse)\nrmse","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# you can data-augmentate your dataset with this:\nfrom itertools import chain\nfrom nltk.corpus import wordnet\n\nsynonyms = wordnet.synsets('creature')\nlemmas = set(chain.from_iterable([word.lemma_names() for word in synonyms]))\nlemmas","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}